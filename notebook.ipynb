{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebUI SparkJobs: http://BHS-NOTE188:4040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BHS-NOTE188:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>jobGPanvel</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e7d4ce6650>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jobs import Sparkinit\n",
    "from json import dump, dumps\n",
    "from utils import formatar_sql\n",
    "spark_start = Sparkinit()\n",
    "import os\n",
    "spark = spark_start.buscar_sessao_spark()\n",
    "\n",
    "print(f\"WebUI SparkJobs: {spark.sparkContext.uiWebUrl}\")\n",
    "spark.getActiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- d_dt_vd: timestamp (nullable = true)\n",
      " |-- n_id_fil: long (nullable = true)\n",
      " |-- n_id_vd_fil: long (nullable = true)\n",
      " |-- v_cli_cod: string (nullable = true)\n",
      " |-- n_vlr_tot_vd: decimal(18,6) (nullable = true)\n",
      " |-- n_vlr_tot_desc: decimal(14,4) (nullable = true)\n",
      " |-- v_cpn_eml: string (nullable = true)\n",
      " |-- tp_pgt: string (nullable = true)\n",
      "\n",
      "-RECORD 0------------------------------\n",
      " d_dt_vd        | 2023-10-12 21:00:00  \n",
      " n_id_fil       | 2356284              \n",
      " n_id_vd_fil    | 34366442231          \n",
      " v_cli_cod      | 016E6FCC4F98832719BC \n",
      " n_vlr_tot_vd   | 55.960000            \n",
      " n_vlr_tot_desc | 13.9900              \n",
      " v_cpn_eml      | NAO                  \n",
      " tp_pgt         | A VISTA              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/* 'Bronze' */\\nSELECT \\n        d_dt_vd,\\n\\tn_id_fil,\\n\\tn_id_vd_fil,\\n\\tv_cli_cod,\\n\\tn_vlr_tot_vd,\\n\\tn_vlr_tot_desc,\\n\\tv_cpn_eml,\\n\\ttp_pgt,\\n        BASE64(CONCAT(CAST(d_dt_vd AS STRING) , CAST(n_id_fil AS STRING) , CAST(n_id_vd_fil AS STRING) , CAST(v_cli_cod AS STRING) , CAST(n_vlr_tot_vd AS STRING) , CAST(n_vlr_tot_desc AS STRING) , CAST(v_cpn_eml AS STRING) , CAST(tp_pgt AS STRING))) AS hash_id\\nFROM vendas_tmp\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "path = os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\VENDAS\")\n",
    "dados = spark.read.format(\"parquet\").load(path)\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "\n",
    "base = [f'CAST({col} AS STRING)' for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final}\n",
    "FROM vendas_tmp\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+---------------+--------------------+-----------------+--------------------+-------------+--------------+\n",
      "|       data_emissao|codigo_filial|id_venda_filial|      codigo_cliente|valor_total_venda|valor_total_desconto|enviado_email|tipo_pagamento|\n",
      "+-------------------+-------------+---------------+--------------------+-----------------+--------------------+-------------+--------------+\n",
      "|2023-10-12 21:00:00|      2356284|    34366442231|016E6FCC4F98832719BC|            55.96|               13.99|        false|       A VISTA|\n",
      "|2023-10-12 21:00:00|      2221184|    35550863931|035D148EADC74B6C6D2F|            31.48|               25.21|        false|              |\n",
      "|2023-10-27 21:00:00|      2188984|    37392732531|030C1011214A3317E850|             6.49|               13.14|        false|       A VISTA|\n",
      "|2023-10-08 21:00:00|      2608284|     3672652731|04710AFAF1FD9C48EBC3|            52.99|               40.27|        false|              |\n",
      "|2023-10-09 21:00:00|       238084|    37059405031|028DBA5BBB05DDF47E4C|            18.54|                8.38|        false|       A VISTA|\n",
      "|2023-10-23 21:00:00|      2687384|      403806931|012F0A4B6592C311F2ED|            31.90|                5.09|         true|              |\n",
      "|2023-10-17 21:00:00|      2617384|     4392793031|0316E487B4F1B6831BA3|           655.26|              259.95|        false|       A VISTA|\n",
      "|2023-10-05 21:00:00|      2352784|     3967276731|052A34441AD2AE1DFD94|            36.98|                0.00|        false|              |\n",
      "|2023-10-29 21:00:00|      2642584|     3422446731|001EC0D3A64CF4F6C941|            93.47|               45.63|        false|       A VISTA|\n",
      "|2023-10-25 21:00:00|      2620184|     3808200231|03755F35E240B8451322|            70.92|               18.91|        false|              |\n",
      "|2023-10-19 21:00:00|      2198784|    35494168831|0516882260A1031D8719|            27.98|                0.00|         true|              |\n",
      "|2023-10-11 21:00:00|      2186184|    36834033731|028D5FE319C8C62D4BFC|            17.98|                1.56|        false|       A VISTA|\n",
      "|2023-10-21 21:00:00|      2631384|     3541135631|03A4F193268E48C0D124|            47.02|                5.13|         true|       A VISTA|\n",
      "|2023-10-29 21:00:00|      2367484|     4267716431|05191F65ECBA674435B7|             7.98|               36.68|        false|              |\n",
      "|2023-10-08 21:00:00|       259084|    35445273831|009ED5A72E6053182284|           147.93|               46.00|        false|              |\n",
      "|2023-10-22 21:00:00|      2198784|    35494845331|0477E33A9B918C7769EF|            87.85|                0.50|        false|       A VISTA|\n",
      "|2023-10-30 21:00:00|       275884|    36185562831|024DCAF27751A0A07A08|            44.69|                2.51|        false|       A VISTA|\n",
      "|2023-10-18 21:00:00|      2188284|    36436975531|04D97DB0EC3122A68972|            26.39|               15.29|        false|       A VISTA|\n",
      "|2023-10-19 21:00:00|      2440984|     4398824331|011016FEF0EE6346E786|            83.91|               25.78|         true|       A VISTA|\n",
      "|2023-10-22 21:00:00|      2648884|     3497829731|0194D2BC60AF2468C836|            40.45|                9.45|        false|       A PRAZO|\n",
      "+-------------------+-------------+---------------+--------------------+-----------------+--------------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/* 'Silver' */\\nSELECT COALESCE(date_format(vt.d_dt_vd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_emissao,\\n       CAST(vt.n_id_fil AS BIGINT) AS codigo_filial,\\n       CAST(vt.n_id_vd_fil AS BIGINT) AS id_venda_filial,\\n       COALESCE(CAST(vt.v_cli_cod AS STRING), '') AS codigo_cliente,\\n       CAST(vt.n_vlr_tot_vd AS DECIMAL(38, 2)) AS valor_total_venda,\\n       CAST(vt.n_vlr_tot_desc AS DECIMAL(38, 2)) AS valor_total_desconto,\\n       CASE\\n           WHEN vt.v_cpn_eml = 'SIM' THEN TRUE\\n           ELSE FALSE\\n       END AS enviado_email,\\n       COALESCE(CAST(vt.tp_pgt AS STRING), '') AS tipo_pagamento\\nFROM vendas_tmp AS vt\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"vendas_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    COALESCE(date_format(vt.d_dt_vd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_emissao,\n",
    "    CAST(vt.n_id_fil AS BIGINT) AS codigo_filial,\n",
    "    CAST(vt.n_id_vd_fil AS BIGINT) AS id_venda_filial,\n",
    "    COALESCE(CAST(vt.v_cli_cod AS STRING), '') AS codigo_cliente,\n",
    "    CAST(vt.n_vlr_tot_vd AS DECIMAL(38, 2)) AS valor_total_venda,\n",
    "    CAST(vt.n_vlr_tot_desc AS DECIMAL(38, 2)) AS valor_total_desconto,\n",
    "    CASE \n",
    "        WHEN vt.v_cpn_eml  = 'SIM' THEN True\n",
    "        ELSE False\n",
    "    END AS enviado_email,\n",
    "    COALESCE(CAST(vt.tp_pgt AS STRING), '') AS tipo_pagamento\n",
    "    \n",
    "FROM vendas_tmp as vt\"\"\")\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- n_id_pdd: long (nullable = true)\n",
      " |-- d_dt_eft_pdd: date (nullable = true)\n",
      " |-- d_dt_entr_pdd: timestamp (nullable = true)\n",
      " |-- v_cnl_orig_pdd: string (nullable = true)\n",
      " |-- v_uf_entr_pdd: string (nullable = true)\n",
      " |-- v_lc_ent_pdd: string (nullable = true)\n",
      " |-- n_vlr_tot_pdd: decimal(38,2) (nullable = true)\n",
      "\n",
      "-RECORD 0-----------------------------\n",
      " n_id_pdd       | 1187021679777       \n",
      " d_dt_eft_pdd   | 2023-09-13          \n",
      " d_dt_entr_pdd  | 2023-09-13 21:49:15 \n",
      " v_cnl_orig_pdd | L                   \n",
      " v_uf_entr_pdd  | RS                  \n",
      " v_lc_ent_pdd   | VIAMAO              \n",
      " n_vlr_tot_pdd  | 19.99               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/* 'Bronze' */\\nSELECT \\n        n_id_pdd,\\n\\td_dt_eft_pdd,\\n\\td_dt_entr_pdd,\\n\\tv_cnl_orig_pdd,\\n\\tv_uf_entr_pdd,\\n\\tv_lc_ent_pdd,\\n\\tn_vlr_tot_pdd, \\n        BASE64(CONCAT(CAST(n_id_pdd AS STRING) , CAST(d_dt_eft_pdd AS STRING) , CAST(d_dt_entr_pdd AS STRING) , CAST(v_cnl_orig_pdd AS STRING) , CAST(v_uf_entr_pdd AS STRING) , CAST(v_lc_ent_pdd AS STRING) , CAST(n_vlr_tot_pdd AS STRING))) AS hash_id\\nFROM pedidos_tmp\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.format(\"parquet\").load(os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\PEDIDOS\"))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = [f'CAST({col} AS STRING)' for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas}, \n",
    "        {base_final}\n",
    "FROM pedidos_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\n[PARSE_SYNTAX_ERROR] Syntax error at or near 'BASE64'.(line 12, pos 70)\n\n== SQL ==\n/* 'Silver' */\nSELECT CAST(pd.n_id_pdd AS BIGINT) AS id_pedido,\n       COALESCE(CAST(pd.d_dt_eft_pdd AS DATE), '') AS data_realizacao_pedido,\n       COALESCE(date_format(pd.d_dt_entr_pdd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_entrega,\n       CASE\n           WHEN pd.v_cnl_orig_pdd = 'L' THEN 'Loja'\n           WHEN pd.v_cnl_orig_pdd = 'A' THEN 'App'\n           WHEN pd.v_cnl_orig_pdd = 'S' THEN 'Site'\n       END AS canal_venda,\n       COALESCE(CAST(pd.v_uf_entr_pdd AS STRING), '') AS UF_pedido,\n       COALESCE(CAST(pd.v_lc_ent_pdd AS STRING), '') AS cidade_entrega,\n       CAST(pd.n_vlr_tot_pdd AS DECIMAL(38, 2)) AS valor_total_pedido BASE64(CAST(n_id_pdd AS STRING)) AS hash_id\n----------------------------------------------------------------------^^^\nFROM pedidos_tmp AS pd\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m      2\u001b[0m dados\u001b[38;5;241m.\u001b[39mcreateOrReplaceTempView(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpedidos_tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m formatar_sql(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m/* \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSilver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m */\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    CAST(pd.n_id_pdd AS BIGINT) AS id_pedido,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m    BASE64(CAST(n_id_pdd AS STRING)) AS hash_id\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124mFROM pedidos_tmp as pd\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     21\u001b[0m query\n",
      "File \u001b[1;32mC:\\spark\\spark-3.4.0-bin-hadoop3\\python\\pyspark\\sql\\session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[1;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\spark\\spark-3.4.0-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\spark\\spark-3.4.0-bin-hadoop3\\python\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mParseException\u001b[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'BASE64'.(line 12, pos 70)\n\n== SQL ==\n/* 'Silver' */\nSELECT CAST(pd.n_id_pdd AS BIGINT) AS id_pedido,\n       COALESCE(CAST(pd.d_dt_eft_pdd AS DATE), '') AS data_realizacao_pedido,\n       COALESCE(date_format(pd.d_dt_entr_pdd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_entrega,\n       CASE\n           WHEN pd.v_cnl_orig_pdd = 'L' THEN 'Loja'\n           WHEN pd.v_cnl_orig_pdd = 'A' THEN 'App'\n           WHEN pd.v_cnl_orig_pdd = 'S' THEN 'Site'\n       END AS canal_venda,\n       COALESCE(CAST(pd.v_uf_entr_pdd AS STRING), '') AS UF_pedido,\n       COALESCE(CAST(pd.v_lc_ent_pdd AS STRING), '') AS cidade_entrega,\n       CAST(pd.n_vlr_tot_pdd AS DECIMAL(38, 2)) AS valor_total_pedido BASE64(CAST(n_id_pdd AS STRING)) AS hash_id\n----------------------------------------------------------------------^^^\nFROM pedidos_tmp AS pd\n"
     ]
    }
   ],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"pedidos_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    CAST(pd.n_id_pdd AS BIGINT) AS id_pedido,\n",
    "    COALESCE(CAST(pd.d_dt_eft_pdd AS DATE), '') AS data_realizacao_pedido,\n",
    "    COALESCE(date_format(pd.d_dt_entr_pdd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_entrega,\n",
    "    CASE \n",
    "        WHEN pd.v_cnl_orig_pdd = 'L' THEN 'Loja'\n",
    "        WHEN pd.v_cnl_orig_pdd = 'A' THEN 'App'\n",
    "        WHEN pd.v_cnl_orig_pdd = 'S' THEN 'Site'\n",
    "    END AS canal_venda,\n",
    "    COALESCE(CAST(pd.v_uf_entr_pdd AS STRING), '') AS UF_pedido,\n",
    "    COALESCE(CAST(pd.v_lc_ent_pdd AS STRING), '') AS cidade_entrega,\n",
    "    CAST(pd.n_vlr_tot_pdd AS DECIMAL(38,2)) AS valor_total_pedido\n",
    "    BASE64(CAST(n_id_pdd AS STRING)) AS hash_id\n",
    "FROM pedidos_tmp as pd\"\"\")\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedidos Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.format(\"parquet\").load(os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\PEDIDO_VENDA\"))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = [f'CAST({col} AS STRING)' for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final} \n",
    "FROM pedido_venda_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"pedido_venda_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver'*/\n",
    "SELECT \n",
    "    CAST(pv.n_id_fil AS BIGINT) AS codigo_filial,\n",
    "    CAST(pv.n_id_vd_fil AS BIGINT) AS id_venda_filial,\n",
    "    CAST(pv.n_id_pdd AS BIGINT) AS id_pedido\n",
    "    BASE64(CONCAT(CAST(n_id_fil AS STRIN), CAST(n_id_vd_fil AS STRING), CAST(n_id_pdd AS STRING))) AS hash_id\n",
    "FROM pedido_venda_tmp as pv\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itens Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.format(\"parquet\").load(os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\ITENS_VENDAS\"))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = [f'CAST({col} AS STRING)' for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final}\n",
    "FROM itens_vendas_tmp\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"itens_vendas_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    CAST(iv.n_id_fil AS BIGINT) AS codigo_filial,\n",
    "    CAST(iv.n_id_vd_fil AS BIGINT) AS id_venda_filial,\n",
    "    CAST(iv.n_id_it AS BIGINT) AS codigo_item_venda,\n",
    "    CASE \n",
    "        WHEN iv.v_rc_elt  = 'SIM' THEN True\n",
    "        ELSE False\n",
    "    END AS com_receita_eletronica,\n",
    "    CASE \n",
    "        WHEN iv.v_it_vd_conv = 'SIM' THEN 'Convênio'\n",
    "        WHEN iv.v_it_vd_conv = 'NAO' AND iv.n_vlr_desc > 0 THEN 'Promoção'\n",
    "        ELSE 'Sem Desconto'\n",
    "    END AS tipo_desconto,\n",
    "    CAST(iv.n_vlr_pis AS DECIMAL(38,2)) AS valor_pis_item,\n",
    "    CAST(iv.n_vlr_vd AS DECIMAL(38,2)) AS valor_final_item,\n",
    "    CAST(iv.n_vlr_desc AS DECIMAL(38,2)) AS valor_desconto_item,\n",
    "    CAST(iv.n_qtd AS BIGINT) AS quantidade_itens,\n",
    "FROM itens_vendas_tmp as iv\"\"\")\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endereços Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.format(\"parquet\").load(os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\ENDERECOS_CLIENTES\"))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = [f'CAST({col} AS STRING)' for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final}\n",
    "FROM enderecos_clientes_tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"enderecos_clientes_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    CAST(ec.v_id_cli AS STRING) AS codigo_cliente,\n",
    "    CAST(ec.n_sq_end AS BIGINT) AS sequencia_endereco_cliente,\n",
    "    COALESCE(date_format(ec.d_dt_exc, 'yyyy-MM-dd HH:mm:ss'), '') AS data_exclusao_endereco,\n",
    "    CAST(ec.v_lcl AS STRING) AS cidade_endereco,\n",
    "    CAST(ec.v_uf AS STRING) AS UF_endereco\n",
    "FROM enderecos_clientes_tmp as ec\"\"\")\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clientes Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.option(\"multiline\",\"true\").format(\"json\").load(os.path.abspath(r\"C:\\Users\\gustavo.lopes\\Documentos\\GitHub\\desafio_panvel-data_engineer\\datalake\\camada_0_transient\\CLIENTES_OPT\"))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=2, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = ['CAST({} AS STRING)'.format(col) for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final}\n",
    "FROM clientes_opt_tmp\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"clientes_opt_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    CAST(co.v_id_cli AS STRING) AS codigo_cliente,\n",
    "    CASE \n",
    "        WHEN co.b_push  = True THEN 'SIM'\n",
    "        WHEN co.b_push  = False THEN 'NÃO'\n",
    "        ELSE ''\n",
    "    END AS autoriza_notificacao_push,\n",
    "    CASE \n",
    "        WHEN co.b_sms  = True THEN 'SIM'\n",
    "        WHEN co.b_sms  = False THEN 'NÃO'\n",
    "        ELSE ''\n",
    "    END AS autoriza_notificacao_sms,\n",
    "    CASE \n",
    "        WHEN co.b_email  = True THEN 'SIM'\n",
    "        WHEN co.b_email  = False THEN 'NÃO'\n",
    "        ELSE ''\n",
    "    END AS autoriza_notificacao_email,\n",
    "    CASE \n",
    "        WHEN co.b_call  = True THEN 'SIM'\n",
    "        WHEN co.b_call  = False THEN 'NÃO'\n",
    "        ELSE ''\n",
    "    END AS autoriza_notificacao_ligacao\n",
    "FROM clientes_opt_tmp as co\"\"\")\n",
    "\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- v_id_cli: string (nullable = true)\n",
      " |-- d_dt_nasc: date (nullable = true)\n",
      " |-- v_sx_cli: string (nullable = true)\n",
      " |-- n_est_cvl: string (nullable = true)\n",
      "\n",
      "-RECORD 0-------------------------\n",
      " v_id_cli  | 0000009DB36F622B7639 \n",
      " d_dt_nasc | 2003-11-14           \n",
      " v_sx_cli  | F                    \n",
      " n_est_cvl | null                 \n",
      "only showing top 1 row\n",
      "\n",
      "\"/* 'Bronze' */\\nSELECT \\n        v_id_cli,\\n\\td_dt_nasc,\\n\\tv_sx_cli,\\n\\tn_est_cvl,\\n        BASE64(CONCAT(CAST(v_id_cli AS STRING) , CAST(d_dt_nasc AS STRING) , CAST(v_sx_cli AS STRING) , CAST(n_est_cvl AS STRING))) AS hash_id\\nFROM clientes_tmp\"\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataframe para verificar a estrutura das colunas e tipos de dados\n",
    "dados = spark.read.format(\"parquet\").load(os.path.abspath(os.path.join(os.getcwd(), \"datalake/camada_0_transient/CLIENTES\")))\n",
    "\n",
    "dados.printSchema()\n",
    "\n",
    "dados.show(n=1, vertical=True)\n",
    "colunas = ',\\n\\t'.join(dados.columns)\n",
    "base = ['CAST({} AS STRING)'.format(col) for col in dados.columns]\n",
    "base_media = ' , '.join(base)\n",
    "base_final = f\"BASE64(CONCAT({base_media})) AS hash_id\"\n",
    "base_final\n",
    "print(dumps(f\"\"\"/* 'Bronze' */\n",
    "SELECT \n",
    "        {colunas},\n",
    "        {base_final}\n",
    "FROM clientes_tmp\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+-----+------------------------+--------------------+\n",
      "|      codigo_cliente|data_nascimento_cliente|idade|genero_biologico_cliente|estado_civil_cliente|\n",
      "+--------------------+-----------------------+-----+------------------------+--------------------+\n",
      "|0000009DB36F622B7639|             2003-11-14|   20|                Feminino|                    |\n",
      "|000000F51C15031D708E|             2008-03-23|   15|                Feminino|                    |\n",
      "|00000F54BE2BBF0E7B13|             1986-02-24|   37|                Feminino|                    |\n",
      "|000013E1FB44D9A9E50F|             1984-12-13|   39|               Masculino|                    |\n",
      "|00001522AD94645C7688|             1992-11-10|   31|                Feminino|              Casado|\n",
      "|0000161185110EE1BBE5|             1975-12-27|   48|                Feminino|                    |\n",
      "|0000269BBD1888477D56|             1961-10-25|   62|               Masculino|                    |\n",
      "|0000289F7EF0375B679D|             1983-11-05|   40|                Feminino|            Solteiro|\n",
      "|00002A10FB7B5E5CB107|             1991-08-19|   32|               Masculino|                    |\n",
      "|00002F84FF8B063A952C|             1975-06-13|   48|                Feminino|                    |\n",
      "|000033354ABAAD3F2FA8|             1964-01-01|   60|                Feminino|            Solteiro|\n",
      "|00003490C16D52FEB4C2|             2004-03-20|   19|                Feminino|                    |\n",
      "|000040FC122DB8AEEF51|             1982-04-06|   41|                Feminino|                    |\n",
      "|000042FA835BDA98ACCE|             1965-05-03|   58|               Masculino|              Casado|\n",
      "|000046B0542EFC2E550A|             1990-06-02|   33|                Feminino|            Solteiro|\n",
      "|00004A80EE1AE5324A9E|             1946-05-14|   77|                        |                    |\n",
      "|00004B9802657262B995|             1996-03-06|   27|                        |                    |\n",
      "|00004CAACD07633F2C95|             1978-11-26|   45|                Feminino|                    |\n",
      "|0000524920EA26B08218|             1999-09-14|   24|                        |                    |\n",
      "|00005651B2086081178C|             1961-06-19|   62|                Feminino|                    |\n",
      "+--------------------+-----------------------+-----+------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/* 'Silver' */\\nSELECT CAST(c.v_id_cli AS STRING) AS codigo_cliente,\\n       COALESCE(CAST(c.d_dt_nasc AS DATE), '') AS data_nascimento_cliente,\\n       CAST(DATEDIFF(CURRENT_DATE(), CAST(c.d_dt_nasc AS DATE)) / 365 AS INT) AS idade,\\n       CASE\\n           WHEN c.v_sx_cli = 'F' THEN 'Feminino'\\n           WHEN c.v_sx_cli = 'M' THEN 'Masculino'\\n           ELSE ''\\n       END AS genero_biologico_cliente,\\n       CASE\\n           WHEN c.n_est_cvl = 1 THEN 'Solteiro'\\n           WHEN c.n_est_cvl = 2 THEN 'Casado'\\n           WHEN c.n_est_cvl = 3 THEN 'Viúvo'\\n           WHEN c.n_est_cvl = 4 THEN 'Desquitado'\\n           WHEN c.n_est_cvl = 5 THEN 'Divorciado'\\n           WHEN c.n_est_cvl = 6 THEN 'Outros'\\n           ELSE ''\\n       END AS estado_civil_cliente\\nFROM clientes_tmp AS c\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a tabela temporária e realizando a consulta que depois usaremos para transformar a camada raw\n",
    "dados.createOrReplaceTempView(\"clientes_tmp\")\n",
    "\n",
    "query = formatar_sql(\"\"\"/* 'Silver' */\n",
    "SELECT \n",
    "    CAST(c.v_id_cli AS STRING) AS codigo_cliente,\n",
    "    COALESCE(CAST(c.d_dt_nasc AS DATE), '') AS data_nascimento_cliente,\n",
    "    CAST(DATEDIFF(CURRENT_DATE(), CAST(c.d_dt_nasc AS DATE)) / 365 AS INT) as idade,\n",
    "    CASE \n",
    "        WHEN c.v_sx_cli  = 'F' THEN 'Feminino'\n",
    "        WHEN c.v_sx_cli  = 'M' THEN 'Masculino'\n",
    "        ELSE '' \n",
    "    END AS genero_biologico_cliente,\n",
    "    CASE \n",
    "        WHEN c.n_est_cvl  = 1 THEN 'Solteiro'\n",
    "        WHEN c.n_est_cvl  = 2 THEN 'Casado'\n",
    "        WHEN c.n_est_cvl  = 3 THEN 'Viúvo'\n",
    "        WHEN c.n_est_cvl  = 4 THEN 'Desquitado'\n",
    "        WHEN c.n_est_cvl  = 5 THEN 'Divorciado'\n",
    "        WHEN c.n_est_cvl  = 6 THEN 'Outros'\n",
    "        ELSE ''\n",
    "    END AS estado_civil_cliente\n",
    "FROM clientes_tmp as c\"\"\")\n",
    "spark.sql(query).show()\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" -- 'Tabela Endereços Clientes parquet'\n",
    "SELECT \n",
    "    CAST(c.v_id_cli AS STRING) AS codigo_cliente,\n",
    "    COALESCE(CAST(c.d_dt_nasc AS DATE), '') AS data_nascimento_cliente,\n",
    "    CASE \n",
    "        WHEN c.v_sx_cli  = 'F' THEN 'Feminino'\n",
    "        WHEN c.v_sx_cli  = 'M' THEN 'Masculino'\n",
    "        ELSE '' \n",
    "    END AS genero_biologico_cliente,\n",
    "    CASE \n",
    "        WHEN c.n_est_cvl  = 1 THEN 'Solteiro'\n",
    "        WHEN c.n_est_cvl  = 2 THEN 'Casado'\n",
    "        WHEN c.n_est_cvl  = 3 THEN 'Viúvo'\n",
    "        WHEN c.n_est_cvl  = 4 THEN 'Desquitado'\n",
    "        WHEN c.n_est_cvl  = 5 THEN 'Divorciado'\n",
    "        WHEN c.n_est_cvl  = 6 THEN 'Outros'\n",
    "        ELSE ''\n",
    "    END AS estado_civil_cliente\n",
    "FROM clientes_tmp as c\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" /* Gold 'Vendas' */\n",
    "SELECT \n",
    "    v.codigo_filial AS codifo_filial,\n",
    "    v.id_venda_filial AS codigo_cupom_venda,\n",
    "    v.data_emissao AS data_emissao,\n",
    "    iv.codigo_item_venda AS codigo_item,\n",
    "    iv.valor_final_item AS valor_unitario,\n",
    "    iv.quantidade_itens AS quantidade,\n",
    "    v.codigo_cliente AS codigo_cliente,\n",
    "    iv.tipo_desconto AS tipo_desconto,\n",
    "    p.canal_venda AS canal_venda\n",
    "FROM vendas AS v\n",
    "INNER JOIN pedido_venda AS pv ON CONCAT(CAST(pv.codigo_filial AS STRING), CAST(pv.id_venda_filial AS STRING)) = CONCAT(CAST(v.codigo_filial AS STRING), CAST(v.id_venda_filial AS STRING))\n",
    "INNER JOIN itens_vendas AS iv ON CONCAT(CAST(iv.codigo_filial AS STRING), CAST(iv.id_venda_filial)) = CONCAT(CAST(v.codigo_filial AS STRING), CAST(v.id_venda_filial AS STRING))\n",
    "INNER JOIN pedidos AS p ON p.id_pedido = pv.id_pedido\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"/* 'Silver' */\\nSELECT COALESCE(date_format(vt.d_dt_vd, 'yyyy-MM-dd HH:mm:ss'), '') AS data_emissao,\\n       CAST(vt.n_id_fil AS BIGINT) AS codigo_filial,\\n       CAST(vt.n_id_vd_fil AS BIGINT) AS id_venda_filial,\\n       COALESCE(CAST(vt.v_cli_cod AS STRING), '') AS codigo_cliente,\\n       CAST(vt.n_vlr_tot_vd AS DECIMAL(38, 2)) AS valor_total_venda,\\n       CAST(vt.n_vlr_tot_desc AS DECIMAL(38, 2)) AS valor_total_desconto,\\n       CASE\\n           WHEN vt.v_cpn_eml = 'SIM' THEN TRUE\\n           ELSE FALSE\\n       END AS enviado_email,\\n       COALESCE(CAST(vt.tp_pgt AS STRING), '') AS tipo_pagamento, \\nhash_id\\nFROM vendas_tmp AS vt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"/* Gold 'Clientes' */\n",
    "SELECT\n",
    "    c.codigo_cliente AS codigo_cliente,\n",
    "    c.data_nascimento_cliente AS data_nascimento,\n",
    "    DATEDIFF('YEAR', CAST(data_nascimento AS DATE), CURRENT_DATE()) as idade,\n",
    "    c.genero_biologico_cliente AS sexo,\n",
    "    ec.UF_endereco AS uf,\n",
    "    ec.cidade_endereco AS cidade,\n",
    "    c.estado_civil_cliente AS estado_civil,\n",
    "    co.autoriza_notificacao_ligacao AS flag_lgpd_call,\n",
    "    co.autoriza_notificacao_sms AS flag_lgpd_sms,\n",
    "    co.autoriza_notificacao_email AS flag_lgpd_email,\n",
    "    co.autoriza_notificacao_push AS flag_lgpd_push\n",
    "FROM clientes AS c\n",
    "INNER JOIN clientes_opt AS co ON co.codigo_cliente = c.codigo_cliente\n",
    "INNER JOIN enderecos_clientes AS ec ON ec.codigo_cliente = c.codigo_cliente\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desafio_panvel-data_engineer-pE6NpJI7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
